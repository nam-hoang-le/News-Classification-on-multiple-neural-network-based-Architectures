{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "85406957",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1421da5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2225 entries, 0 to 2224\n",
      "Data columns (total 2 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   category  2225 non-null   object\n",
      " 1   text      2225 non-null   object\n",
      "dtypes: object(2)\n",
      "memory usage: 34.9+ KB\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Load dataset\n",
    "file_path = 'data/bbc-text.csv'\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Display basic information about the dataset\n",
    "data.info()\n",
    "\n",
    "# Display the first few rows of the dataset\n",
    "data.head()\n",
    "\n",
    "# Tokenize the text\n",
    "tokenizer = Tokenizer(num_words=5000, oov_token=\"<OOV>\")\n",
    "tokenizer.fit_on_texts(data['text'])\n",
    "\n",
    "# Convert text to sequences\n",
    "sequences = tokenizer.texts_to_sequences(data['text'])\n",
    "\n",
    "# Pad the sequences\n",
    "padded_sequences = pad_sequences(sequences, padding='post')\n",
    "\n",
    "# Encode the labels\n",
    "label_encoder = LabelEncoder()\n",
    "data['label'] = label_encoder.fit_transform(data['category'])\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(padded_sequences, data['label'], test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "80a73e83",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class LSTMCell:\n",
    "    def __init__(self, input_dim, hidden_dim):\n",
    "        self.input_dim = input_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.Wf = np.random.randn(hidden_dim, hidden_dim + input_dim) * 0.01\n",
    "        self.bf = np.zeros((hidden_dim, 1))\n",
    "        self.Wi = np.random.randn(hidden_dim, hidden_dim + input_dim) * 0.01\n",
    "        self.bi = np.zeros((hidden_dim, 1))\n",
    "        self.Wc = np.random.randn(hidden_dim, hidden_dim + input_dim) * 0.01\n",
    "        self.bc = np.zeros((hidden_dim, 1))\n",
    "        self.Wo = np.random.randn(hidden_dim, hidden_dim + input_dim) * 0.01\n",
    "        self.bo = np.zeros((hidden_dim, 1))\n",
    "        \n",
    "    def forward(self, xt, a_prev, c_prev):\n",
    "        concat = np.concatenate((a_prev, xt), axis=0)\n",
    "        \n",
    "        ft = self.sigmoid(np.dot(self.Wf, concat) + self.bf)\n",
    "        it = self.sigmoid(np.dot(self.Wi, concat) + self.bi)\n",
    "        cct = np.tanh(np.dot(self.Wc, concat) + self.bc)\n",
    "        c_next = ft * c_prev + it * cct\n",
    "        ot = self.sigmoid(np.dot(self.Wo, concat) + self.bo)\n",
    "        a_next = ot * np.tanh(c_next)\n",
    "        \n",
    "        return a_next, c_next\n",
    "\n",
    "    def sigmoid(self, x):\n",
    "        return 1 / (1 + np.exp(-x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "caffb1d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Initialize parameters\n",
    "input_dim = X_train.shape[1]\n",
    "hidden_dim = 128\n",
    "output_dim = len(label_encoder.classes_)\n",
    "\n",
    "# Initialize LSTM cell\n",
    "lstm_cell = LSTMCell(input_dim, hidden_dim)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6caed86d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def forward_propagation(X, lstm_cell):\n",
    "    m, T_x = X.shape\n",
    "    n_a, _ = lstm_cell.Wf.shape\n",
    "    \n",
    "    a = np.zeros((n_a, m, T_x))\n",
    "    c = np.zeros((n_a, m, T_x))\n",
    "    a_next = np.zeros((n_a, m))\n",
    "    c_next = np.zeros((n_a, m))\n",
    "    \n",
    "    for t in range(T_x):\n",
    "        xt = X[:, t]\n",
    "        a_next, c_next = lstm_cell.forward(xt, a_next, c_next)\n",
    "        a[:, :, t] = a_next\n",
    "        c[:, :, t] = c_next\n",
    "    \n",
    "    return a, c\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f63a2f1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def compute_loss(y, y_hat):\n",
    "    m = y.shape[0]\n",
    "    loss = -1 / m * np.sum(y * np.log(y_hat) + (1 - y) * np.log(1 - y_hat))\n",
    "    return loss\n",
    "\n",
    "def train(X, y, lstm_cell, epochs=10, learning_rate=0.01):\n",
    "    for epoch in range(epochs):\n",
    "        a, _ = forward_propagation(X, lstm_cell)\n",
    "        y_hat = a[:, :, -1]\n",
    "        loss = compute_loss(y, y_hat)\n",
    "        print(f\"Epoch {epoch+1}/{epochs}, Loss: {loss}\")\n",
    "        # Backpropagation and parameter update code goes here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d1611b9a",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "all the input arrays must have same number of dimensions, but the array at index 0 has 2 dimension(s) and the array at index 1 has 1 dimension(s)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Evaluate the model (Example code, implement evaluation logic as needed)\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m a, _ \u001b[38;5;241m=\u001b[39m forward_propagation(X_test, lstm_cell)\n\u001b[0;32m      3\u001b[0m y_hat \u001b[38;5;241m=\u001b[39m a[:, :, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n",
      "Cell \u001b[1;32mIn[5], line 12\u001b[0m, in \u001b[0;36mforward_propagation\u001b[1;34m(X, lstm_cell)\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(T_x):\n\u001b[0;32m     11\u001b[0m     xt \u001b[38;5;241m=\u001b[39m X[:, t]\n\u001b[1;32m---> 12\u001b[0m     a_next, c_next \u001b[38;5;241m=\u001b[39m lstm_cell\u001b[38;5;241m.\u001b[39mforward(xt, a_next, c_next)\n\u001b[0;32m     13\u001b[0m     a[:, :, t] \u001b[38;5;241m=\u001b[39m a_next\n\u001b[0;32m     14\u001b[0m     c[:, :, t] \u001b[38;5;241m=\u001b[39m c_next\n",
      "Cell \u001b[1;32mIn[3], line 15\u001b[0m, in \u001b[0;36mLSTMCell.forward\u001b[1;34m(self, xt, a_prev, c_prev)\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, xt, a_prev, c_prev):\n\u001b[1;32m---> 15\u001b[0m     concat \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mconcatenate((a_prev, xt), axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m     17\u001b[0m     ft \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msigmoid(np\u001b[38;5;241m.\u001b[39mdot(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mWf, concat) \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbf)\n\u001b[0;32m     18\u001b[0m     it \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msigmoid(np\u001b[38;5;241m.\u001b[39mdot(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mWi, concat) \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbi)\n",
      "\u001b[1;31mValueError\u001b[0m: all the input arrays must have same number of dimensions, but the array at index 0 has 2 dimension(s) and the array at index 1 has 1 dimension(s)"
     ]
    }
   ],
   "source": [
    "\n",
    "# Evaluate the model (Example code, implement evaluation logic as needed)\n",
    "a, _ = forward_propagation(X_test, lstm_cell)\n",
    "y_hat = a[:, :, -1]\n",
    "# Convert predictions to class labels and calculate accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45dd0488",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Nam",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
